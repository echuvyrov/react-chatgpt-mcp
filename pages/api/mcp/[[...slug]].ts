import type { NextApiRequest, NextApiResponse } from "next";
import { existsSync, readFileSync } from "node:fs";
import path from "node:path";
import OpenAI from "openai";
import { z } from "zod";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";

export const config = {
  api: {
    bodyParser: false
  }
};

const MCP_METHODS = new Set(["POST", "GET", "DELETE"]);
const WIDGET_URI = "ui://widget/hello.html";
const widgetPath = path.join(process.cwd(), "public", "widget", "index.html");

function loadWidgetHtml() {
  if (!existsSync(widgetPath)) {
    return `<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Hello Widget</title>
  </head>
  <body>
    <div style="padding:24px;font-family:system-ui">Run <code>npm run build:widget</code> to generate the React widget.</div>
  </body>
</html>`;
  }

  return readFileSync(widgetPath, "utf8");
}

function createHelloServer() {
  const server = new McpServer({ name: "hello-world", version: "0.1.0" });
  const widgetHtml = loadWidgetHtml();

  server.registerResource("hello-widget", WIDGET_URI, {}, async () => ({
    contents: [
      {
        uri: WIDGET_URI,
        mimeType: "text/html+skybridge",
        text: widgetHtml,
        _meta: { "openai/widgetPrefersBorder": false }
      }
    ]
  }));

  const openai = process.env.OPENAI_API_KEY
    ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
    : null;

  server.registerTool(
    "show_hello",
    {
      title: "Show hello widget",
      description:
        "Returns the hello widget and (optionally) a greeting generated by the OpenAI SDK.",
      inputSchema: z.object({
        use_model: z.boolean().optional()
      }),
      _meta: {
        "openai/outputTemplate": WIDGET_URI,
        "openai/toolInvocation/invoking": "Showing Hello World",
        "openai/toolInvocation/invoked": "Hello World ready"
      }
    },
    async (args) => {
      let greeting = "Hello World";

      if (args?.use_model && openai) {
        const model = process.env.OPENAI_MODEL || "gpt-5";
        const response = await openai.responses.create({
          model,
          input: "Say 'Hello World' as a short greeting."
        });

        const text = response.output_text?.trim();
        if (text) {
          greeting = text;
        }
      }

      return {
        content: [{ type: "text", text: greeting }],
        structuredContent: { greeting }
      };
    }
  );

  return server;
}

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method === "OPTIONS") {
    res.writeHead(204, {
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "POST, GET, OPTIONS",
      "Access-Control-Allow-Headers": "content-type, mcp-session-id",
      "Access-Control-Expose-Headers": "Mcp-Session-Id"
    });
    res.end();
    return;
  }

  if (!req.method || !MCP_METHODS.has(req.method)) {
    res.status(405).send("Method Not Allowed");
    return;
  }

  res.setHeader("Access-Control-Allow-Origin", "*");
  res.setHeader("Access-Control-Expose-Headers", "Mcp-Session-Id");

  const server = createHelloServer();
  const transport = new StreamableHTTPServerTransport({
    sessionIdGenerator: undefined,
    enableJsonResponse: true
  });

  res.on("close", () => {
    transport.close();
    server.close();
  });

  try {
    await server.connect(transport);
    await transport.handleRequest(req, res);
  } catch (error) {
    console.error("Error handling MCP request:", error);
    if (!res.headersSent) {
      res.status(500).send("Internal server error");
    }
  }
}
